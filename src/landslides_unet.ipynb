{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4854857b",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeca8fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from glob import glob\n",
    "from os import path as osp\n",
    "\n",
    "import contextily as cx\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "import getuseragent as gua\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrsgis\n",
    "import rasterio\n",
    "import requests\n",
    "import richdem as rd\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal\n",
    "from pandas_profiling import ProfileReport\n",
    "from rasterio import features\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import *\n",
    "import multiprocessing\n",
    "\n",
    "from shapely.geometry import box\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ddcd9",
   "metadata": {},
   "source": [
    "## Environment settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcbb28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "seed = 26\n",
    "np.random.seed(seed)  # set a seed for reproducible results\n",
    "\n",
    "CRS = \"epsg:3857\"\n",
    "headers = {\"User-Agent\": gua.UserAgent('desktop').Random()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346651f",
   "metadata": {},
   "source": [
    "# Acquire data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f0d16",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/working'\n",
    "\n",
    "# create a working directory to hold data files\n",
    "try:\n",
    "    os.makedirs(data_dir, exist_ok=False)\n",
    "except OSError:\n",
    "    shutil.rmtree(data_dir)\n",
    "    os.makedirs(data_dir, exist_ok=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bf6eb",
   "metadata": {},
   "source": [
    "## Landslide data\n",
    "\n",
    "Courtesy of the [California Geological Survey](https://www.conservation.ca.gov/cgs/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c4d2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# copy landslide data to working directory\n",
    "landslide_src_path = shutil.copy(\n",
    "    '../data/CGS_Landslide_Inventory/landslide_sources.gpkg', osp.join(data_dir, 'landslide_sources.gpkg'))\n",
    "\n",
    "landslide_dep_path = shutil.copy(\n",
    "    '../data/CGS_Landslide_Inventory/landslide_deposits.gpkg', osp.join(data_dir, 'landslide_deposits.gpkg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the gpkg data using geopandas\n",
    "scarps = gpd.read_file(landslide_src_path).to_crs(CRS)\n",
    "deposits = gpd.read_file(landslide_dep_path).to_crs(CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569b491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97be2c48",
   "metadata": {},
   "source": [
    "### Visualize landslide scarps and deposits\n",
    "\n",
    "[Basemap documentation](https://contextily.readthedocs.io/en/latest/providers_deepdive.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f2fbc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# plot the landslide sources\n",
    "src_ax = scarps.plot(figsize=(8, 8), alpha=0.5, color='green', edgecolor='k')\n",
    "src_ax.set_title('Landslide Scarps')\n",
    "src_ax.set_xlabel('Longitude')\n",
    "src_ax.set_ylabel('Latitude')\n",
    "src_ax.grid(True)\n",
    "cx.add_basemap(src_ax, source=cx.providers.Esri.WorldShadedRelief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the landslide deposits\n",
    "dep_ax = deposits.plot(figsize=(8, 8), alpha=0.5, color='red', edgecolor='k')\n",
    "dep_ax.set_title('Landslide Deposits')\n",
    "dep_ax.set_xlabel('Longitude')\n",
    "dep_ax.set_ylabel('Latitude')\n",
    "dep_ax.grid(True)\n",
    "cx.add_basemap(dep_ax, source=cx.providers.Esri.WorldShadedRelief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2877915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df527a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc63706",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# get the extent of the landslide data in different formats\n",
    "lst_bounds = [max(scarps.total_bounds[i], deposits.total_bounds[i])\n",
    "              for i in range(len(scarps.total_bounds))]\n",
    "pg_bounds = box(*lst_bounds)\n",
    "str_bounds = \",\".join(str(x) for x in lst_bounds)\n",
    "\n",
    "print(str_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20b55c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "bounds_poly = gpd.GeoSeries(pg_bounds)\n",
    "bounds_poly = bounds_poly.set_crs(CRS)\n",
    "bounds_ax = bounds_poly.plot(\n",
    "    figsize=(8, 8), alpha=0.5, color='gray', edgecolor='red', linewidth=3)\n",
    "bounds_ax.set_title('Research Area Extent')\n",
    "cx.add_basemap(bounds_ax, source=cx.providers.Esri.WorldShadedRelief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_poly.to_file(osp.join(data_dir, 'research_extent.geojson'), driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622df47",
   "metadata": {},
   "source": [
    "## Geological data\n",
    "\n",
    "[Source](https://www.sciencebase.gov/arcgis/rest/services/Catalog/5888bf4fe4b05ccb964bab9d/MapServer/3): State Geologic Map Compilation ([SGMC](https://www.sciencebase.gov/catalog/item/5888bf4fe4b05ccb964bab9d)) geodatabase of the conterminous United States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97041c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the geology data from the CGS Mapserver API\n",
    "response = requests.get('http://gis.conservation.ca.gov/server/rest/services/CGS/Geologic_Map_of_California/FeatureServer/12/query', params={\n",
    "    \"geometry\": str_bounds,\n",
    "    \"geometryType\": \"esriGeometryEnvelope\",\n",
    "    \"spatialRel\": \"esriSpatialRelIntersects\",\n",
    "    \"where\": \"1=1\",\n",
    "    \"units\": \"esriSRUnit_Meter\",\n",
    "    \"outFields\": \"GENERAL_LITHOLOGY,AGE,DESCRIPTION\",\n",
    "    \"returnGeometry\": \"true\",\n",
    "    \"returnTrueCurves\": \"false\",\n",
    "    \"returnIdsOnly\": \"false\",\n",
    "    \"returnCountOnly\": \"false\",\n",
    "    \"returnDistinctValues\": \"false\",\n",
    "    \"returnExtentOnly\": \"false\",\n",
    "    \"sqlFormat\": \"none\",\n",
    "    \"featureEncoding\": \"esriDefault\",\n",
    "    \"f\": \"geojson\",\n",
    "}, headers=headers)\n",
    "\n",
    "print(response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53278cac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    print(f'{time.ctime()} | Successfully retrieved geological data')\n",
    "    # write the landslide data to a geojson file\n",
    "    geology_path = osp.join(data_dir, 'geology.geojson')\n",
    "    with open(geology_path, 'w') as f:\n",
    "        geojson.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f'{time.ctime()} | ERROR {response.status_code}: Failed to retrieve geological data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a523dde",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# load the geology data into a geopandas dataframe and set the correct CRS\n",
    "geology = gpd.read_file(geology_path).to_crs(CRS)\n",
    "geology = geology.clip(mask=bounds_poly)\n",
    "display(geology)\n",
    "\n",
    "geo_ax = geology.plot(\n",
    "    figsize=(15, 10), column='GENERAL_LITHOLOGY', legend=True, alpha=0.5, edgecolor='k')\n",
    "geo_ax.set_title('Generalized Lithology of the Study Area')\n",
    "cx.add_basemap(geo_ax, source=cx.providers.Esri.WorldShadedRelief)\n",
    "leg = geo_ax.get_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a statistical profile using the pandas profiling lib\n",
    "profile = ProfileReport(pd.DataFrame(geology.drop(\n",
    "    columns='geometry')), title=\"Geology Data Profile\", explorative=False)\n",
    "\n",
    "display(profile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fbdd6",
   "metadata": {},
   "source": [
    "The statistical report shows a nearly 1-1 correlation between the data features: lithology (_GENERAL_LITHOLOGY_), age (_AGE_), & the description (_DESCRIPTION_). While the description is helpful to a human reader, it is not informative for the model. Since our goal is to determine how rock type affects landslide risk, we will use the lithology feature rather than the age feature in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a4f87",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# remove the excess features\n",
    "lithology = geology.drop(columns=['AGE', 'DESCRIPTION'], inplace=False)\n",
    "lithology.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c1a6a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "display(lithology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955565f",
   "metadata": {},
   "source": [
    "## Elevation derivatives\n",
    "\n",
    "DEM data from the USGS 3DEP database.\n",
    "\n",
    "Slope, aspect curvature rasters calculated using [`richdem`](https://richdem.com).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = scarps.total_bounds\n",
    "# corners = [(xmin, ymin), (xmin, ymax), (xmax, ymin), (xmax, ymax)]\n",
    "\n",
    "delta_x = round(abs(xmax - xmin)/10, -2)\n",
    "delta_y = round(abs(ymax - ymin)/10, -2)\n",
    "\n",
    "# every pixel is 10m\n",
    "print(delta_x, delta_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the number closest to n and divisible by m\n",
    "def closestNumber(n, m):\n",
    "    # Find the quotient\n",
    "    q = int(n / m)\n",
    "\n",
    "    # 1st possible closest number\n",
    "    n1 = m * q\n",
    "\n",
    "    # 2nd possible closest number\n",
    "    if((n * m) > 0):\n",
    "        n2 = (m * (q + 1))\n",
    "    else:\n",
    "        n2 = (m * (q - 1))\n",
    "\n",
    "    # if true, then n1 is the required closest number\n",
    "    if (abs(n - n1) < abs(n - n2)):\n",
    "        return n1\n",
    "\n",
    "    # else n2 is the required closest number\n",
    "    return n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a2043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cdcbb1d",
   "metadata": {},
   "source": [
    "### Set tile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b16a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_SIZE = 64  # set the tile size to TILE_SIZExTILE_SIZE pixels\n",
    "\n",
    "# approx image size to be ~10m per pixel & divisible into tile_size X tile_size tiles\n",
    "size_x = closestNumber(delta_x, TILE_SIZE)\n",
    "size_y = closestNumber(delta_y, TILE_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74a964",
   "metadata": {},
   "source": [
    "### Download DEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f778cc1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# download dem from 3DEPELEVATION imageserver\n",
    "image_data = requests.get(url=\"https://elevation.nationalmap.gov/arcgis/rest/services/3DEPElevation/ImageServer/exportImage\",\n",
    "                          params={\"bbox\": str_bounds, \"size\": f\"{size_x},{size_y}\", \"bboxSR\": CRS, \"imageSR\": CRS, \"f\": \"image\", \"format\": \"tiff\", \"adjustAspectRatio\": \"true\", }, stream=True, headers=headers)\n",
    "\n",
    "print(image_data.status_code)\n",
    "\n",
    "if image_data.status_code == 200:\n",
    "    with open(osp.join(data_dir, 'dem.tif'), 'wb') as f:\n",
    "        image_data.raw.decode_content = True\n",
    "        shutil.copyfileobj(image_data.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = rd.LoadGDAL(osp.join(data_dir, 'dem.tif'), no_data=-9999)\n",
    "\n",
    "rd.rdShow(dem, axes=True, cmap='Greys_r', figsize=(10, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f82d9",
   "metadata": {},
   "source": [
    "### Derive slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37d04d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "slope = rd.TerrainAttribute(dem, attrib='slope_degrees')\n",
    "rd.rdShow(slope, axes=True, cmap='magma', figsize=(8, 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186da51c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rd.SaveGDAL(osp.join(data_dir, 'slope.tif'), slope/slope.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47111247",
   "metadata": {},
   "source": [
    "### Derive aspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3695b7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "aspect = rd.TerrainAttribute(dem, attrib='aspect')\n",
    "rd.rdShow(aspect, axes=True, cmap='jet', figsize=(8, 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbad98",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rd.SaveGDAL(osp.join(data_dir, 'aspect.tif'), aspect/360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898239df",
   "metadata": {},
   "source": [
    "### Derive curvature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088df40",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "curvature = rd.TerrainAttribute(dem, attrib='curvature')\n",
    "rd.rdShow(curvature, axes=True, cmap='jet_r', figsize=(8, 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_norm = (curvature + abs(curvature.min())) / curvature.max()\n",
    "rd.SaveGDAL(osp.join(data_dir, 'curvature.tif'), c_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a50886",
   "metadata": {},
   "source": [
    "# Preprocess data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135095a4",
   "metadata": {},
   "source": [
    "## Rasterize shapefile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert shapefile to a raster\n",
    "def shp2raster(example_raster_path, shp_gdf, output_path, attr=None):\n",
    "\n",
    "    # read in vector\n",
    "    vector = shp_gdf.copy()\n",
    "\n",
    "    # get list of geometries for all features in vector file\n",
    "    geom = [shapes for shapes in vector.geometry]\n",
    "\n",
    "    if attr is not None:\n",
    "        # create a numeric unique value for each attribute/feature\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(vector[attr])\n",
    "        vector[attr] = le.transform(vector[attr])\n",
    "        vector[attr] = [x+1 for x in vector[attr]]\n",
    "\n",
    "        # create tuples of geometry, value pairs, where value is the attribute value you want to burn\n",
    "        geom = ((geom, value)\n",
    "                for geom, value in zip(vector.geometry, vector[attr]))\n",
    "\n",
    "    # open example raster\n",
    "    raster = rasterio.open(example_raster_path)\n",
    "\n",
    "    # rasterize vector using the shape and raster CRS\n",
    "    rasterized = features.rasterize(geom,\n",
    "                                    out_shape=raster.shape,\n",
    "                                    fill=0,\n",
    "                                    out=None,\n",
    "                                    transform=raster.transform,\n",
    "                                    all_touched=False,\n",
    "                                    default_value=1,\n",
    "                                    dtype=None)\n",
    "\n",
    "    # rd.SaveGDAL(output_path, rasterized)\n",
    "\n",
    "    kwargs = raster.meta\n",
    "    kwargs.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        compress='lzw')\n",
    "\n",
    "    with rasterio.open(output_path, 'w', **kwargs) as dst:\n",
    "        dst.write_band(1, rasterized.astype(rasterio.float32))\n",
    "\n",
    "    return rasterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690faeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30239b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the shapefiles to rasters\n",
    "scarps_rast = shp2raster(osp.join(data_dir, 'dem.tif'),\n",
    "                         scarps, output_path=osp.join(data_dir, 'scarps.tif'))\n",
    "\n",
    "deposits_rast = shp2raster(osp.join(\n",
    "    data_dir, 'dem.tif'), deposits, output_path=osp.join(data_dir, 'deposits.tif'))\n",
    "\n",
    "lithology_rast = shp2raster(osp.join(data_dir, 'dem.tif'), lithology, output_path=osp.join(\n",
    "    data_dir, 'lithology.tif'), attr='GENERAL_LITHOLOGY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae87fe7",
   "metadata": {},
   "source": [
    "### Visualize rasterized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76a09f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot scarps raster\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax.set_title('Rasterized Landslide Scarps')\n",
    "# ax.set_xlabel('Longitude')\n",
    "# ax.set_ylabel('Latitude')\n",
    "ax.grid(True)\n",
    "show(scarps_rast, ax=ax, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daaa423",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot deposits raster\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax.set_title('Rasterized Landslide Deposits')\n",
    "# ax.set_xlabel('Longitude')\n",
    "# ax.set_ylabel('Latitude')\n",
    "ax.grid(True)\n",
    "show(deposits_rast, ax=ax, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383aec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lithology raster\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax.set_title('Rasterized Lithology')\n",
    "# ax.set_xlabel('Longitude')\n",
    "# ax.set_ylabel('Latitude')\n",
    "ax.grid(True)\n",
    "show(lithology_rast, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343e13e",
   "metadata": {},
   "source": [
    "## Create a composite raster of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379618fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a composite raster of the data\n",
    "def composite(rasters, output_path):\n",
    "\n",
    "    # open the first raster in the list\n",
    "    with rasterio.open(rasters[0]) as rast:\n",
    "        meta = rast.meta\n",
    "\n",
    "    # update the metadata to reflect the composite raster # of layers\n",
    "    meta.update(count=len(rasters))\n",
    "\n",
    "    # read each raster layer and write it to the composite raster\n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        for id, raster in enumerate(rasters, start=1):\n",
    "            with rasterio.open(raster) as rast:\n",
    "                dst.writeband(id, rast.read(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54025da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f74643a5",
   "metadata": {},
   "source": [
    "### Check raster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_bands = glob(data_dir + '/*.tif')\n",
    "band_titles = [osp.basename(rast).split('.')[0] for rast in multi_bands]\n",
    "\n",
    "# check to ensure the rasters have consistent sizes\n",
    "for raster in multi_bands:\n",
    "    r = gdal.Open(raster)\n",
    "    print(osp.basename(raster).split('.')[0]+\":\", r.RasterYSize, r.RasterXSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f0a13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "stack, meta = es.stack([osp.join(data_dir, 'slope.tif'),\n",
    "                        # osp.join(data_dir, 'slope.tif'),\n",
    "                        # osp.join(data_dir, 'lithology.tif')],\n",
    "                        osp.join(data_dir, 'curvature.tif'),\n",
    "                       osp.join(data_dir, 'aspect.tif')],\n",
    "                       osp.join(data_dir, 'composite.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(stack[0, :, :], cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378d808",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "### Tile the rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ac9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rasters\n",
    "\n",
    "# # labels\n",
    "# _, scarp_labels = pyrsgis.raster.read(\n",
    "#     osp.join(data_dir, 'scarps.tif'), bands=1)\n",
    "\n",
    "# _, deposit_labels = pyrsgis.raster.read(\n",
    "#     osp.join(data_dir, 'deposits.tif'), bands=1)\n",
    "\n",
    "# # features\n",
    "# _, comp_feat = pyrsgis.raster.read(\n",
    "#     osp.join(data_dir, 'composite.tif'), bands='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarp_labels = scarps_rast.astype(np.uint8)\n",
    "deposit_labels = deposits_rast.astype(np.uint8)\n",
    "# comp_feat = stack.astype(np.float32)\n",
    "comp_feat = stack.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6689a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all negatives to 0\n",
    "# tmp = np.clip(scarp_labels, a_min=0, a_max=np.inf)\n",
    "scarp_labels = np.clip(scarp_labels, a_min=0, a_max=np.inf) # np.dstack((tmp, scarp_labels))\n",
    "print(scarp_labels.shape)\n",
    "\n",
    "# tmp = np.clip(deposit_labels, a_min=0, a_max=np.inf)\n",
    "deposit_labels = np.clip(deposit_labels, a_min=0, a_max=np.inf) # np.dstack((tmp, deposit_labels))\n",
    "print(deposit_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182ca27",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# reshape features\n",
    "comp_feat = comp_feat.reshape(*scarp_labels.shape[:2], -1)\n",
    "print(comp_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_split = size_x/TILE_SIZE\n",
    "y_split = size_y/TILE_SIZE\n",
    "\n",
    "X = np.concatenate([np.hsplit(col, x_split) for col in \n",
    "                   np.vsplit(comp_feat, y_split)])\n",
    "\n",
    "y_scarps = np.concatenate([np.hsplit(col, x_split)\n",
    "                           for col in np.vsplit(scarp_labels, y_split)])\n",
    "\n",
    "y_deposits = np.concatenate([np.hsplit(col, x_split)\n",
    "                             for col in np.vsplit(deposit_labels, y_split)])\n",
    "\n",
    "print(X.shape, y_scarps.shape, y_deposits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ee170",
   "metadata": {},
   "source": [
    "### Augment the data and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b710a83",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y = np.expand_dims(y_scarps.astype(np.uint8), axis=-1) \n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(p=0.5, seed=seed),  # 50% chance to flip horizontally\n",
    "    iaa.Flipud(p=0.5, seed=seed),  # 50% chance to flip vertically\n",
    "    # iaa.Rot90((1, 3)),  # rotate by 90, 180 or 270 degrees\n",
    "    # iaa.PiecewiseAffine(scale=(0.01, 0.05))\n",
    "])\n",
    "\n",
    "X_aug, y_aug = seq(images=X, segmentation_maps=y)\n",
    "\n",
    "# combine the original and augmented images\n",
    "X_scarps = np.vstack((X, X_aug))\n",
    "y_scarps = np.vstack((y, y_aug))[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29528ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y_deposits.astype(np.uint8)  # convert masks to boolean\n",
    "y = np.expand_dims(y_deposits.astype(np.uint8), axis=-1) \n",
    "\n",
    "X_aug, y_aug = seq(images=X, segmentation_maps=y)\n",
    "\n",
    "# combine the original and augmented images\n",
    "X_deposits = np.vstack((X, X_aug))\n",
    "y_deposits = np.vstack((y, y_aug))[..., 0]\n",
    "\n",
    "print(X_scarps.shape, y_scarps.shape, X_deposits.shape, y_deposits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e86fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # normalize the data\n",
    "X_scarps_norm = tf.image.per_image_standardization(X_scarps).numpy()\n",
    "X_deposits_norm = tf.image.per_image_standardization(X_deposits).numpy()\n",
    "# X_norm = tf.image.per_image_standardization(X).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6d5b9",
   "metadata": {},
   "source": [
    "## Visualize augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c739c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3): # get three random samples\n",
    "    n = np.random.randint(0, len(X))\n",
    "\n",
    "    f = plt.figure(figsize=(10, 10)) # make a figure\n",
    "\n",
    "    # plot the composite tile image\n",
    "    ax1 = f.add_subplot(1, 4, 1)\n",
    "    ax1.title.set_text(f'Image {n}')\n",
    "    plt.imshow(X_scarps_norm[n])\n",
    "\n",
    "    # plot the scarps mask\n",
    "    ax2 = f.add_subplot(1, 4, 2)\n",
    "    ax2.title.set_text(f'Scarps Mask {n}')\n",
    "    plt.imshow(y_scarps[n], cmap='gray')\n",
    "\n",
    "    # ax3 = f.add_subplot(1, 4, 3)\n",
    "    # ax3.title.set_text(f'Deposits Image {n}')\n",
    "    # plt.imshow(X_deposits_norm[n], cmap='gray')\n",
    "\n",
    "    # plot the deposits mask\n",
    "    ax4 = f.add_subplot(1, 4, 3)\n",
    "    ax4.title.set_text(f'Deposits Mask {n}')\n",
    "    plt.imshow(y_deposits[n], cmap='gray')\n",
    "\n",
    "    plt.show(block=True) # show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd517ec1",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d97432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_filters):\n",
    "\n",
    "    x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c43de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "\n",
    "    f = conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D((2, 2))(f)\n",
    "    \n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c52a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "\n",
    "    x = layers.Conv2DTranspose(n_filters, (2, 2), strides=2, padding=\"same\")(x)\n",
    "    x = layers.Concatenate()([x, conv_features])\n",
    "    x = conv_block(x, n_filters)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f779185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "626c53d3",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model(input_shape, n_classes):\n",
    "\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    n = input_shape[0]/2\n",
    "\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, n)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, n*2)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, n*4)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, n*8)\n",
    "\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = conv_block(p4, n*16)\n",
    "\n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, n*8)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, n*4)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, n*2)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, n)\n",
    "\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(n_classes, 1, padding=\"same\",\n",
    "                            activation=\"sigmoid\")(u9)\n",
    "\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"unet_model\")\n",
    "\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602404ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdfb450a",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9666456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "TRAIN_SIZE = 0.7\n",
    "VALID_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = y.shape[-1]\n",
    "INPUT_SHAPE = (TILE_SIZE, TILE_SIZE, X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829eb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = build_unet_model(input_shape=INPUT_SHAPE, n_classes=N_CLASSES)\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52f2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d291647",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(unet, to_file=osp.join('..', 'refs', 'model.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e8bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea50fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "unet.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# free up RAM in case the model definition cells were run multiple times\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03aa7e",
   "metadata": {},
   "source": [
    "# Train model to identify deposits\n",
    "## Define model inputs and parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429581f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_deposits_norm, y_deposits, test_size=TEST_SIZE, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780c702",
   "metadata": {},
   "source": [
    "### Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e069b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "output_dir = f'../models/'\n",
    "file_name = 'deposits_unet.hdf5'\n",
    "file_path = osp.join(output_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    file_path, verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# keep track of the model training progression\n",
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "callbacks = [checkpoint,\n",
    "             tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
    "             tf.keras.callbacks.TensorBoard(\n",
    "                 log_dir=osp.join('..', 'deposits_logs')),\n",
    "             history]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0674c8",
   "metadata": {},
   "source": [
    "## Train the deposits model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd717a13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "results = unet.fit(X_train, y_train, batch_size=32,\n",
    "                   epochs=50,\n",
    "                   validation_split=VALID_SIZE,\n",
    "                   callbacks=callbacks,\n",
    "                   use_multiprocessing=True,\n",
    "                   workers=multiprocessing.cpu_count()-1,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf2fc7",
   "metadata": {},
   "source": [
    "## Evaluate the deposits model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dba6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(file_path)\n",
    "\n",
    "# use the model to make predictions on the reserved test data\n",
    "score = best_model.evaluate(x=X_test, y=y_test, verbose=2)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b3e1c",
   "metadata": {},
   "source": [
    "# Train the model to identify scarps\n",
    "## Define model inputs and parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scarps_norm, y_scarps, test_size=TEST_SIZE, shuffle=True, random_state=seed)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_norm, y_scarps, test_size=TEST_SIZE, shuffle=True, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4393d",
   "metadata": {},
   "source": [
    "### Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab686d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "output_dir = f'../models/'\n",
    "file_name = 'scarps_unet.hdf5'\n",
    "file_path = osp.join(output_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5af776",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    file_path, verbose=2, save_best_only=True, mode='min')\n",
    "\n",
    "# keep track of the model training progression\n",
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "callbacks = [checkpoint,\n",
    "             tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=osp.join('..', 'scarps_logs')),\n",
    "             history]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb51b0",
   "metadata": {},
   "source": [
    "## Train the scarps model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = unet.fit(X_train, y_train, batch_size=32,\n",
    "                   epochs=50,\n",
    "                   validation_split=VALID_SIZE,\n",
    "                   callbacks=callbacks,\n",
    "                   use_multiprocessing=True,\n",
    "                   workers=multiprocessing.cpu_count()-1,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349f261",
   "metadata": {},
   "source": [
    "## Evaluate the scarps model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45804d4d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(file_path)\n",
    "\n",
    "# use the model to make predictions on the reserved test data\n",
    "score = best_model.evaluate(x=X_test, y=y_test, verbose=2)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e2b83",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf34d545",
   "metadata": {},
   "source": [
    "# Use the trained models to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9407671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6153bfb2",
   "metadata": {},
   "source": [
    "## View the model training metrics online with TensorBoard\n",
    "\n",
    "[Open Tensorboard](https://tensorboard.dev/experiment/mNL39anoRmKK0QWHeoVeaQ/#scalars)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
